{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Deep Learning With Tensorflow for Computer vision\n",
        "\n",
        "Par **Mr Abdoulaye Balde** <br>\n",
        "[Github](https://github.com/abdoulayegk/ODC-Formaton )  <br>\n",
        "[Twitter](https://twitter.com/abdoulayegk)\n"
      ],
      "metadata": {
        "id": "QIaCNFt4fKq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "L’ensemble de données que nous allons utiliser est très connu par les data scientists, il s’agit du Dataset MNIST, ce dernier rassemble près de 60000 images de 28×28 pixels de nombres écrits à la main avec les nombres en numérique comme variable cible. L’objectif de notre modèle sera de reconnaître le nombre écrit sur l’image.\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "eM6ylXtqa1dT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2OfXiXNScC1"
      },
      "outputs": [],
      "source": [
        "# Importer les librairies nécessaires\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "# Importer les données\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici nous allons jeter un coup d’œil sur un échantillons aléatoire d’images avec leurs labels correspondant.  \n",
        "\n"
      ],
      "metadata": {
        "id": "fZ20XS5vbEwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "j = 1\n",
        "\n",
        "for i in np.random.choice(np.arange(0, len(y_train)), size = 6):\n",
        "    # Image\n",
        "    img = X_train[i]\n",
        "\n",
        "    # Subplot nous permet de selectionner une des sous-figures parmi une grille. Dans notre cas la grille\n",
        "    # a 2 lignes et 3 colonnes.\n",
        "    plt.subplot(2, 3, j)\n",
        "    j = j + 1\n",
        "\n",
        "    # Suppresion des axes\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Affichage de la figure en niveaux de gris\n",
        "    plt.imshow(img, cmap='gray', interpolation='None')\n",
        "\n",
        "    # Modification du titre de la figure\n",
        "    plt.title('Label: ' + str(y_train[i]))"
      ],
      "metadata": {
        "id": "X8SWBtsrah-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prétraitement des données\n",
        "Après le chargement de vos données, vous devez vous assurer qu’elles soient prêtes pour la phase d’entraînement. Pour cela vous appliquerez quelques transformations à ces dernières. Notamment redimensionner, normaliser et encoder les données.\n",
        "\n",
        "Mais pas de panique, encore une fois nous vous accompagnerons dans le processus et chaque prétraitement sera expliqué.\n",
        "\n",
        "Redimensionnement : Une particularité des algorithmes de machine learning et deep learning est qu’ils ne prennent pas de matrices en entrée. Ce qui vous amène à transformer vos matrices de 28×28 en vecteurs de taille 784.\n",
        "* Normalisation : Cette étape n’est pas obligatoire pour l’entraînement de votre modèle mais peut booster sa performance, la normalisation est appliquée en divisant chaque pixel par 255.  \n",
        "* Encodage : La transformation des labels en vecteurs catégoriels permet d’améliorer la précision de prédiction."
      ],
      "metadata": {
        "id": "mR-g05aYbVo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Redimensionnement\n",
        "X_train = X_train.reshape((-1,28*28))\n",
        "X_test = X_test.reshape((-1,28*28))\n",
        "\n",
        "# Normalisation\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# One hot encodding (tranformation en vecteurs categoriels)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "nb_classes = len(np.unique(y_train)) # Compte le nombre de classes distinctes\n",
        "y_train = to_categorical(y_train, dtype=\"int\", num_classes = nb_classes) # à exécuter qu'une seule fois\n",
        "y_test = to_categorical(y_test, dtype=\"int\", num_classes = nb_classes) # à exécuter qu'une seule fois"
      ],
      "metadata": {
        "id": "2ILpXb3RbLv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Définition du modèle :\n",
        "Maintenant que vos données sont (vraiment) prêtes, vous pouvez passer à la modélisation de votre réseau de neurones. C’est là que vous allez construire votre modèle couche par couche.\n",
        "\n"
      ],
      "metadata": {
        "id": "aRUBMSkFcFgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_pixel = X_train.shape[1] # Nombre de pixels d'un vecteur (d'une image)\n",
        "\n",
        "# Instanciation de la couche d'entrée\n",
        "input_layer = Input(shape=nb_pixel)\n",
        "# Instanciation de la première couche cachée\n",
        "first_hidden = Dense(units=20, activation=\"relu\")\n",
        "# Ajout d'une deuxième couche cachée\n",
        "second_hidden = Dense(units=14, activation=\"relu\")\n",
        "# Ajout de la couche de sortie\n",
        "output_layer = Dense(units=nb_classes, activation=\"softmax\")\n",
        "\n",
        "# Construction du model\n",
        "model = Sequential([\n",
        "                    input_layer,\n",
        "                    first_hidden,\n",
        "                    second_hidden,\n",
        "                    output_layer\n",
        "])"
      ],
      "metadata": {
        "id": "wPyqZbO5b6cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilation du modèle :\n",
        "La méthode compile configure le processus d’entraînement du modèle en spécifiant 3 paramètres importants.\n",
        "\n",
        "* loss : paramètre qui indique au modèle sur quelle fonction de perte se baser pour calculer l’erreur et l’optimiser. Ici nous utiliserons la « categorical_crossentropy »\n",
        "* optimizer : ce paramètre définit l’algorithme d’optimisation que nous allons utiliser pour faire la descente de gradient de la fonction perte. On choisit l’optimiseur « adam » qui donne en générale de bons résultats sur un grand ensemble de problème\n",
        "* metrics : paramètre servant à choisir les métriques d’évaluation du modèle pendant le processus d’entraînement. La métrique spécifiée pour ce modèle est l’accuracy (précisions), la plus utilisée pour les problèmes de classification.\n",
        "L’exécution de la cellule suivante compilera votre modèle et le rendra enfin prêt pour être entraîné."
      ],
      "metadata": {
        "id": "inStXcTlchG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "igBb-v8ScS_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrainement du modèle\n",
        "\n",
        "Il y'a des parameters a passer comme arguments:\n",
        "* batch_size : le nombre d’échantillons de données que contiendra un batch\n",
        "* epoch : le nombre d’epochs nécessaire à l’entraînement du modèle\n",
        "* validation_split : le pourcentage des données qui serviront pour l’évaluation de notre modèle pendant son entraînement."
      ],
      "metadata": {
        "id": "yMg4grz-dBH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, batch_size=200, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "id": "2pDKmBW9c4_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation du modèle\n",
        "\n",
        "Pour afficher la précision d’entraînement et de validation en fonction des epochs."
      ],
      "metadata": {
        "id": "O35FG9qxdtK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Afichage du graphe de precision d'apprentissage\n",
        "plt.plot(range(1,20+1),\n",
        "         history.history[\"accuracy\"],\n",
        "         label=\"Training Accuracy\",\n",
        "         color=\"red\")\n",
        "\n",
        "# Afichage du graphe de precision de vaidation\n",
        "plt.plot(range(1,20+1),\n",
        "         history.history[\"val_accuracy\"],\n",
        "         label=\"Validation Accuracy\",\n",
        "         color=\"blue\")\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Afficher l'accuracy et la loss finale\n",
        "score = model.evaluate(X_test,y_test)\n",
        "print(\"Fonction Perte : {:.2f}\".format(score[0]))\n",
        "print(\"Precision : {:.2f}\".format(score[1]))"
      ],
      "metadata": {
        "id": "mJVdBlZIdgFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00yrn3DUd_3V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}